Metadata-Version: 2.4
Name: tokenoptimizer
Version: 0.1.0
Summary: Track and optimize LLM API usage and costs
Home-page: https://github.com/yourusername/tokenoptimizer
Author: TokenOptimizer Team
Author-email: info@tokenoptimizer.com
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: requests
Requires-Dist: python-dotenv
Provides-Extra: dev
Requires-Dist: pytest; extra == "dev"
Requires-Dist: mock; extra == "dev"
Provides-Extra: openai
Requires-Dist: openai>=0.27.0; extra == "openai"
Provides-Extra: anthropic
Requires-Dist: anthropic>=0.7.0; extra == "anthropic"
Provides-Extra: mistral
Requires-Dist: mistralai>=0.0.1; extra == "mistral"
Provides-Extra: all
Requires-Dist: openai>=0.27.0; extra == "all"
Requires-Dist: anthropic>=0.7.0; extra == "all"
Requires-Dist: mistralai>=0.0.1; extra == "all"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# TokenOptimizer SDK

A Python SDK for tracking and optimizing LLM API usage, costs, and performance.

## Installation

```bash
pip install tokenoptimizer
```

Or install with specific provider support:

```bash
pip install tokenoptimizer[openai]     # For OpenAI support
pip install tokenoptimizer[anthropic]  # For Anthropic support
pip install tokenoptimizer[mistral]    # For Mistral support
pip install tokenoptimizer[all]        # For all providers
```

## Usage

### Basic Usage with OpenAI

```python
from tokenoptimizer import tracked_completion
from openai import OpenAI

client = OpenAI()

# Wrap your existing completions call with tracked_completion
response = tracked_completion(
    model="gpt-4",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Generate a short poem about AI."}
    ],
    endpoint_name="poetry_generator",  # Optional tag for your feature/endpoint
    provider_client=client
)

# Use the response as you normally would
print(response.choices[0].message.content)
```

### Basic Usage with Anthropic

```python
from tokenoptimizer import tracked_completion
from anthropic import Anthropic

client = Anthropic()

response = tracked_completion(
    model="claude-3-haiku",
    messages=[
        {"role": "user", "content": "Explain quantum computing in simple terms."}
    ],
    endpoint_name="explanations",  # Optional tag for your feature/endpoint
    provider_client=client
)

print(response.content)
```

### Manually Tracking Usage

If you need more control or want to track usage manually:

```python
from tokenoptimizer import track_usage

# After making your API call and retrieving response
track_usage(
    model="gpt-4",
    prompt_tokens=150,
    completion_tokens=50,
    total_tokens=200,
    latency_ms=1200,
    endpoint_name="summarization"
)
```

### Configuration

You can configure the SDK with:

```python
from tokenoptimizer.utils import set_config

set_config(
    api_url="https://your-tokenoptimizer-api.com/api/log",
    timeout=5,  # Request timeout in seconds
    debug=True  # Enable debug mode
)
```

Or use environment variables:

```
TOKENOPTIMIZER_API_URL=https://your-tokenoptimizer-api.com/api/log
TOKENOPTIMIZER_DEBUG=true
```

## Features

- ðŸ“Š Track token usage, latency, and model selection
- ðŸ’° Calculate estimated costs based on latest pricing
- ðŸ”„ Zero-latency integration with existing code
- ðŸ§© Support for multiple LLM providers (OpenAI, Anthropic, Mistral)

## Supported Providers

- âœ… OpenAI (gpt-3.5-turbo, gpt-4, etc.)
- âœ… Anthropic (claude-3-opus, claude-3-sonnet, claude-3-haiku, etc.)
- âœ… Mistral AI (mistral-small, mistral-medium, mistral-large, etc.)

## License

This project is licensed under the MIT License - see the LICENSE file for details. 
